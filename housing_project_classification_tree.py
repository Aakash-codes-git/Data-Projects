# -*- coding: utf-8 -*-
"""Housing Project Classification Tree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ystENNSBLxPSfI1d_cXQiltmX6YnLTDx
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
df_housing = pd.read_csv('train.csv')

df_housing['Over200K'] = 'No'
for x in range(0, len(df_housing['SalePrice'])):
  if df_housing['SalePrice'][x] > 200000:
    df_housing['Over200K'][x] = 'Yes'

# check for null value
df_housing.isnull().sum()

# imputing null values
df_housing1 = df_housing.copy()
df_housing1['LotFrontage'] = df_housing['LotFrontage'].fillna(value=0)
df_housing1['GarageYrBlt'] = df_housing['GarageYrBlt'].fillna(value=df_housing1['GarageYrBlt'].median())
df_housing1['MasVnrArea'] = df_housing['MasVnrArea'].fillna(value=0)

# droping predictors ' OverallCondition' because contains subjective praisal opinion
df_housing2 = df_housing1.copy()
df_housing2 = df_housing1.drop(columns=['OverallCond','OverallQual'])

# dropping predictors with correlation  < 0.1 and > -0.1 to SalePrices
df_housing2.corr()['SalePrice']
df_housing3 = df_housing2.copy()
drop_list = ['Id', 'BsmtFinSF2', 'LowQualFinSF', 'BsmtHalfBath', '3SsnPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']
df_housing3 = df_housing2.drop(columns=drop_list)

df_housing3.corr()['SalePrice']

# Group categorical and numerical columns
df_housing4 = df_housing3.copy()
cvar_list = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'RoofStyle', 'RoofMatl', 'Exterior1st',
             'Exterior2nd', 'MasVnrType','ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional',
             'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']

df_housing4[cvar_list] = df_housing4[cvar_list].astype('category')

nvar_list = ['LotFrontage', 'LotArea', 'YearBuilt','YearRemodAdd', 'MasVnrArea',
             'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'BsmtFullBath',
             'FullBath', 'HalfBath', 'BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces', 'GarageYrBlt',
             'GarageCars', 'GarageArea', 'WoodDeckSF','EnclosedPorch','ScreenPorch', 'OpenPorchSF', 'SalePrice']
df_housing4[nvar_list] = df_housing4[nvar_list].astype('float64')

df_housing5 = df_housing4.copy()
# Dummy code
df_housing5 = pd.get_dummies(df_housing5, prefix_sep='_')

# standardization of numeric value
#df_housing5[nvar_list] = (df_housing5[nvar_list] - df_housing5[nvar_list].mean())/df_housing5[nvar_list].std()
#print(df_housing5.columns.values)
df_housing6 = df_housing5.copy()

# find mode value for each categorical variables
df_mode = df_housing4[cvar_list].mode()
df_mode1 = pd.get_dummies(df_mode, prefix_sep='_')
mode = []
for x in df_mode1:
  if df_mode1[x][0] > 0:
    mode.append(x)
mode

# drop mode value as redundent dummies
for x in mode:
  if x in df_housing6:
    df_housing6 = df_housing6.drop(columns=x)
df_housing7 = df_housing6.drop(columns=['Over200K_No','SalePrice'])

from sklearn.model_selection import train_test_split

# train, test data partition split

test_size = 0.2

dfpartition = df_housing7

df_nontest, df_test = train_test_split(dfpartition, test_size = test_size, random_state = 3)

from sklearn.tree import DecisionTreeClassifier

dv = 'Over200K_Yes'
y = df_nontest[dv]
X = df_nontest.drop(columns=[dv])

from sklearn.tree import export_graphviz
from io import StringIO
import pydotplus
from IPython.display import Image

def summary_tree(model_object):
  dot_data = StringIO()
  export_graphviz(model_object, out_file=dot_data, filled=True,
                  rounded=True, special_characters=True, feature_names=X.columns.values,
                  class_names=['0', '1'])
  graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
  output_imagefile = 'tree.png'
  graph.write_png(output_imagefile)
  return output_imagefile

kfolds = 5
# Setting depth
maximum_depth = 15
minimum_depth = 1

param_grid = {'max_depth':list(range(minimum_depth, maximum_depth+1))}

from sklearn.model_selection import GridSearchCV

gridsearch = GridSearchCV(DecisionTreeClassifier(criterion='entropy', random_state=1), param_grid, scoring='roc_auc', cv=kfolds, n_jobs=-1)
gridsearch.fit(X,y)

clf_bpt = gridsearch.best_estimator_  # best pruned tree

Image(summary_tree(clf_bpt))

y_test_actual = df_test[dv]
 X_test = df_test.drop(columns=[dv])

 from sklearn.metrics import roc_auc_score
 print(roc_auc_score(y_test_actual, clf_bpt.predict_proba(X_test)[:,1]))

clf_bpt.get_depth()

import numpy as np

def get_treepaths(dtc, df):
    rules_list = []
    values_path = []
    values = dtc.tree_.value

    def RevTraverseTree(tree, node, rules, pathValues):
        try:
            prevnode = tree[2].index(node)
            leftright = '<='
            pathValues.append(values[prevnode])
        except ValueError:
            # failed, so find it as a right node - if this also causes an exception, something's really f'd up
            prevnode = tree[3].index(node)
            leftright = '>'
            pathValues.append(values[prevnode])

        # now let's get the rule that caused prevnode to -> node
        p1 = df.columns[tree[0][prevnode]]
        p2 = tree[1][prevnode]
        rules.append(str(p1) + ' ' + leftright + ' ' + str(p2))

        # if we've not yet reached the top, go up the tree one more step
        if prevnode != 0:
            RevTraverseTree(tree, prevnode, rules, pathValues)

    # get the nodes which are leaves
    leaves = dtc.tree_.children_left == -1
    leaves = np.arange(0,dtc.tree_.node_count)[leaves]

    # build a simpler tree as a nested list: [split feature, split threshold, left node, right node]
    thistree = [dtc.tree_.feature.tolist()]
    thistree.append(dtc.tree_.threshold.tolist())
    thistree.append(dtc.tree_.children_left.tolist())
    thistree.append(dtc.tree_.children_right.tolist())

    # get the decision rules for each leaf node & apply them
    for (ind,nod) in enumerate(leaves):

        # get the decision rules
        rules = []
        pathValues = []
        RevTraverseTree(thistree, nod, rules, pathValues)

        pathValues.insert(0, values[nod])
        pathValues = list(reversed(pathValues))

        rules = list(reversed(rules))

        rules_list.append(rules)
        values_path.append(pathValues)

    for i in range(len(rules_list)):

      print('\nLeaf node ID =', i+1)
      print('Path =', rules_list[i])
      distro = sum(values_path[i][-1])
      print('sample =', int(sum(distro)))
      print('value =', list([int(distro[0]), int(distro[1])]))
      predicted_class = 1 if distro[1] > distro[0] else 0
      print('class = ', predicted_class)

    return None

get_treepaths(dtc=clf_bpt, df=df_nontest)

